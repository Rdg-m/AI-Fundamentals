{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4664ccad",
   "metadata": {},
   "source": [
    "# **M√©tricas de Classifica√ß√£o ‚Äî M√≥dulo 2, Notebook 2/4**\n",
    "\n",
    "---\n",
    "\n",
    "## √çndice\n",
    "\n",
    "1. [Problema de Classifica√ß√£o](#problema-classificacao)\n",
    "2. [Tipos de Classifica√ß√£o](#tipos-classificacao)\n",
    "3. [O que √© um Classificador?](#o-que-e-classificador)\n",
    "4. [M√©tricas de Avalia√ß√£o](#metricas-avaliacao)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45779148",
   "metadata": {},
   "source": [
    "<a id='problema-classificacao'></a> \n",
    "\n",
    "### **O que √© um problema de classifica√ß√£o?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fb1de8",
   "metadata": {},
   "source": [
    "A classifica√ß√£o √© o processo de reconhecimento, compreens√£o e agrupamento de objetos e ideias em categorias predefinidas. Utilizando conjuntos de dados de treinamento previamente categorizados, algoritmos de classifica√ß√£o em machine learning conseguem categorizar novos dados de forma precisa.\n",
    "\n",
    "Esses algoritmos analisam dados de entrada para prever a probabilidade de que novos dados perten√ßam a uma das categorias estabelecidas.\n",
    "\n",
    "Em termos simples, a classifica√ß√£o √© uma forma de reconhecimento de padr√µes, em que os algoritmos identificam padr√µes nos dados de treinamento e aplicam esse conhecimento a novos conjuntos de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ad8d48",
   "metadata": {},
   "source": [
    "**Motiva√ß√£o:** Suponha que voc√™ tenha um conjunto de dados com caracter√≠sticas de v√°rios clientes de um banco que desejam obter empr√©stimos. Seus dados possuem um conjunto de caracter√≠sticas desses clientes como idade, renda, n√≠vel de educa√ß√£o, entre outros. \n",
    "\n",
    "Baseando-se no conjunto de caracter√≠sticas fornecidas, voc√™ deseja **classificar** os clientes entre aqueles que ter√£o o empr√©stimo aprovado e aqueles que n√£o ter√£o o empr√©stimo aprovado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9017eac",
   "metadata": {},
   "source": [
    "<a id='tipos-classificacao'></a>\n",
    "\n",
    "Formalmente, em problemas de classifica√ß√£o o objetivo √© prever uma *class label*, uma lista de possibilidades pr√©-determinadas e que s√£o vari√°veis discretas.\n",
    "\n",
    "Na motiva√ß√£o acima, a nossa *class label* era se a pessoa teria o cr√©dito aprovado ou n√£o. Perceba que a resposta s√≥ assume dois valores poss√≠veis, sim ou n√£o (1 ou 0 em linguagem matem√°tica). Al√©m disso, podemos chamar essa vari√°vel de discreta porque ela s√≥ assume dois valores poss√≠veis, ela \"d√° um salto\" de 0 para 1.\n",
    "\n",
    "Os problemas de classifica√ß√£o podem ser separados em:\n",
    "\n",
    "- Classifica√ß√£o bin√°ria (binary classification)\n",
    "- Classifica√ß√£o multiclasse (Multi-class classification)\n",
    "\n",
    "- Classifica√ß√£o multir√≥tulo (Multi-label Classification)- Classifica√ß√£o desbalanceada (Imbalanced Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8156a241",
   "metadata": {},
   "source": [
    "<a id='classificacao-binaria'></a>\n",
    "### **Classifica√ß√£o bin√°ria (binary classification)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dad84b8",
   "metadata": {},
   "source": [
    "O objetivo da classifica√ß√£o bin√°ria √© classificar cada observa√ß√£o (vetor de caracter√≠sticas) tendo como possibilidade de resposta (label) exatamente duas classes. Voc√™ pode pensar na classifica√ß√£o bin√°ria como tentar responder uma pergunta do tipo sim ou n√£o. Um email √© um spam? sim ou n√£o. Um cliente ter√° seu pedido de empr√©stimo aprovado? sim ou n√£o.\n",
    "\n",
    "Neste cen√°rio, podemos dizer que a class label √© mutuamente exclusiva. Ou seja, ou uma observa√ß√£o √© classificada como sim ou ela √© classificada como n√£o. √â imposs√≠vel uma observa√ß√£o ser classificada como sim e n√£o ao mesmo tempo.\n",
    "\n",
    "üìù **Observa√ß√£o**: No contexto de classifica√ß√£o bin√°ria, √© comum usar True ou False, positivo ou negativo, 1 ou 0 para se referir a uma resposta do tipo \"sim ou n√£o\". N√£o se preocupe, s√£o apenas maneiras diferentes de se referir a mesma coisa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6da1ca",
   "metadata": {},
   "source": [
    "### **Classifica√ß√£o multiclasse (Multi-class classification)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61b36fa",
   "metadata": {},
   "source": [
    "Semelhante a classifica√ß√£o bin√°ria, na classifica√ß√£o multiclasse tamb√©m queremos classificar cada observa√ß√£o no nosso conjunto de dados. Por√©m, nossa lista de possibilidades pr√©-determinadas agora √© maior que duas. Por√©m, de maneira semelhante, as class labels ainda s√£o mutuamente exclusivas e discretas.\n",
    "\n",
    "**Exemplo:** Se tivermos um conjunto de dados com caracter√≠sticas de alunos da FEA, podemos querer classific√°-los de acordo com o curso em que eles est√£o matriculados. As poss√≠veis respostas (class labels) s√£o (i) Administra√ß√£o, (ii) Economia, (iii) Contabilidade ou (iv) Atu√°ria. Perceba que um aluno n√£o pode estar matr√≠culado em dois ou mais destes cursos ao mesmo tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eff6678",
   "metadata": {},
   "source": [
    "### **Classifica√ß√£o multir√≥tulo (Multi-label Classification)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b5496d",
   "metadata": {},
   "source": [
    "Semelhante a classifica√ß√£o multiclasse, queremos classificar cada observa√ß√£o na nossa base de dados em uma lista de possibilidades pr√©-determinadas em duas ou mais class labels. Por√©m, no caso da classifica√ß√£o multir√≥tulo, as labels agora n√£o s√£o mais mutuamente exclusivas.\n",
    "\n",
    "Pense em um problema em que queremos classificar um vetor de caracter√≠sticas em X, Y, e/ou Z. Em um problema de multir√≥tulo, √© totalmente poss√≠vel que uma observa√ß√£o seja classificada como X e Y ou Y e Z **ao mesmo tempo**. Isso pode parecer estranho, mas um exemplo deixa tudo mais claro.\n",
    "\n",
    "**Exemplo:** Pense agora que temos um conjunto de dados de v√°rios filmes e queremos classific√°-los de acordo com seus g√™neros. Perceba agora que os g√™neros de um filme n√£o s√£o mutuamente exclusivas, √© totalmente poss√≠vel que um filme seja de com√©dia e ao mesmo tempo seja um filme de a√ß√£o ou que um filme seja de terror e de suspense psicol√≥gico ao mesmo tempo. Ou seja, √© totalmente poss√≠vel que cada observa√ß√£o tenha uma ou mais labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d6cc09",
   "metadata": {},
   "source": [
    "### **Classifica√ß√£o desbalanceada (Imbalanced Classification)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5740a11a",
   "metadata": {},
   "source": [
    "A classifica√ß√£o desbalanceada n√£o √© exatamente uma categoria de classifica√ß√£o diferente, mas sim um ponto de aten√ß√£o que devemos ter quando trabalhamos com qualquer problema de classifica√ß√£o abordado nos t√≥picos anteriores.\n",
    "\n",
    "Ela acontece quando as class labels do nosso conjunto de dados n√£o est√£o balanceadas. Neste caso, as observa√ß√µes ser√£o classificadas majoritamente de um tipo e poucas ser√£o classificadas de outro.\n",
    "\n",
    "**Exemplo:** Suponha que uma doen√ßa rara afeta apenas 1% da popula√ß√£o.\n",
    "\n",
    "Se nossa base de dados for representativa da popula√ß√£o, apenas cerca de 1% deveria ser classificado como positivo para a doen√ßa e 99% deveria ser negativo.\n",
    "\n",
    "Apesar de n√£o ser uma categoria diferenciada de classifica√ß√£o, √© importante que tenhamos no√ß√£o se estivermos trabalhando com um problema desse tipo porque as t√©cnicas e modelos usuais que veremos podem n√£o funcionar muito bem neste contexto. \n",
    "\n",
    "Outro ponto de aten√ß√£o necess√°rio √© quando tivermos avaliando um modelo nesse contexto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8fed51",
   "metadata": {},
   "source": [
    "<a id='o-que-e-classificador'></a>\n",
    "\n",
    "### **O que √© um classificador?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61158d1f",
   "metadata": {},
   "source": [
    "Um classificador √© um **algoritmo** de Machine Learning que √© utilizado para mapear cada vetor de caracter√≠sticas no conjunto de dados a uma categoria espec√≠fica. Conforme nossas defini√ß√µes iniciais, pense no classificador como um **conjunto de regras** que definem a metodologia utilizada para que o modelo que voc√™ est√° treinando produza o resultado esperado.\n",
    "\n",
    "Estes algoritmos, de maneira geral, implementam m√©todos matem√°ticos e estat√≠sticos sofisticados para classificar as observa√ß√µes do conjunto de dados.\n",
    "\n",
    "Alguns exemplos de classificadores que veremos ao longo do notebook s√£o:\n",
    "- KNN (K-Nearest Neighbor)\n",
    "- Naive Bayes\n",
    "- Regress√£o Log√≠stica\n",
    "- M√°quinas de Vetores de Suporte (SVC)\n",
    "- √Årvores de Decis√£o\n",
    "\n",
    "Passaremos em mais detalhes por cada um deles, ent√£o n√£o se preocupe em querer entender todos neste momento. Apenas tenha em mente que cada um desses classificadores segue um algoritmo espec√≠fico para produzir o resultado final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f8b0ae",
   "metadata": {},
   "source": [
    "### **Pr√°tica**\n",
    "\n",
    "Visando tornar o material um pouco mais pr√°tico, ao longo de alguns t√≥picos abaixo iremos utilizar um dataset de pr√°tica fornecido pela biblioteca Scikit-Learn. O Scikit-Learn (ou somente sklearn) √© a principal biblioteca de Machine Learning do Python e fundamental para nosso objetivo neste notebook. Dessa forma, recomendamos fortemente que o leitor dedique um tempo a consultar a documenta√ß√£o e, se necess√°rio, procurar fontes externas para entender o seu uso.\n",
    "\n",
    "[Documenta√ß√£o Scikit-Learn](https://scikit-learn.org/stable/)\n",
    "\n",
    "**Descri√ß√£o do Dataset: An√°lise de Vinhos Italianos**\n",
    "\n",
    "Origem e Objetivo:\n",
    "\n",
    "Este dataset cont√©m os resultados de uma an√°lise qu√≠mica realizada em vinhos cultivados na mesma regi√£o da It√°lia, mas provenientes de tr√™s produtores (ou cultivares/castas) distintos. O objetivo principal √© classificar os vinhos em um desses tr√™s produtores com base em suas caracter√≠sticas qu√≠micas. √â um exemplo cl√°ssico para problemas de reconhecimento de padr√µes e classifica√ß√£o.\n",
    "\n",
    "**Caracter√≠sticas (Features) Analisadas:**\n",
    "\n",
    "As 13 caracter√≠sticas presentes no dataset representam diferentes componentes qu√≠micos e propriedades f√≠sicas dos vinhos, que podem ajudar a distinguir suas origens:\n",
    "\n",
    "√Ålcool: Refere-se ao teor alco√≥lico do vinho, uma das suas caracter√≠sticas fundamentais.\n",
    "\n",
    "√Åcido M√°lico: Um dos principais √°cidos org√¢nicos encontrados nas uvas e no vinho, contribui para o sabor e acidez.\n",
    "\n",
    "Cinzas: Representa o conte√∫do mineral do vinho, obtido ap√≥s a evapora√ß√£o e queima do res√≠duo seco. Indica a quantidade total de minerais.\n",
    "\n",
    "Alcalinidade das Cinzas: Mede a alcalinidade do res√≠duo mineral (cinzas), o que pode estar relacionado com a composi√ß√£o do solo do vinhedo.\n",
    "\n",
    "Magn√©sio: Quantidade deste mineral espec√≠fico, importante para diversas rea√ß√µes bioqu√≠micas na uva e no vinho.\n",
    "\n",
    "Fen√≥is Totais: Compostos org√¢nicos que afetam o sabor, cor e sensa√ß√£o na boca (adstring√™ncia) do vinho. Incluem taninos e outros antioxidantes.\n",
    "\n",
    "Flavonoides: Um subgrupo importante de compostos fen√≥licos, conhecidos por seus benef√≠cios √† sa√∫de e impacto nas caracter√≠sticas sensoriais do vinho (cor, corpo, adstring√™ncia).\n",
    "Fen√≥is N√£o Flavonoides: Outro grupo de compostos fen√≥licos que tamb√©m contribuem para as propriedades do vinho.\n",
    "\n",
    "Proantocianidinas: S√£o taninos condensados, um tipo espec√≠fico de flavonoide que contribui significativamente para a adstring√™ncia (aquela sensa√ß√£o de \"boca seca\") e cor dos vinhos tintos.\n",
    "\n",
    "Intensidade da Cor: Medida quantitativa da intensidade da cor do vinho.\n",
    "\n",
    "Tonalidade (Matiz): Descreve a cor espec√≠fica do vinho (por exemplo, se √© mais para o vermelho-rubi, vermelho-p√∫rpura, etc.).\n",
    "\n",
    "DO280/DO315 de vinhos dilu√≠dos: Uma medi√ß√£o espectrofotom√©trica (Densidade √ìptica em comprimentos de onda de 280nm e 315nm). Essa raz√£o pode estar relacionada √† concentra√ß√£o de prote√≠nas e outros compostos fen√≥licos que absorvem luz UV, ajudando a caracterizar o vinho.\n",
    "\n",
    "Prolina: Um amino√°cido frequentemente encontrado em uvas e vinhos, cuja concentra√ß√£o pode variar dependendo da variedade da uva e das condi√ß√µes de cultivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70e55cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso n√£o tenha o sklearn instalado, instale-o com o comando (descomente a linha abaixo):\n",
    "# pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495d0d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Come√ßamos importando as bibliotecas necess√°rias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tendo o sklearn instalado, come√ßamos importando nosso dataset de classifica√ß√£o\n",
    "# Para praticar os conceitos que iremos percorrer\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Carregamos o dataset\n",
    "wine = load_wine()\n",
    "# E o transformamos em um DataFrame do Pandas\n",
    "df = pd.DataFrame(data=wine.data, columns=wine.feature_names)\n",
    "# Adicionamos a coluna de classes\n",
    "df['target'] = wine.target\n",
    "\n",
    "# Tradu√ß√£o das colunas para o portugues\n",
    "df = df.rename(columns={'alcohol': '√Ålcool',\n",
    "                        'malic_acid': '√Åcido M√°lico',\n",
    "                        'ash': 'Cinzas',\n",
    "                        'alcalinity_of_ash': 'Alcalinidade das Cinzas',\n",
    "                        'magnesium': 'Magn√©sio',\n",
    "                        'total_phenols': 'Fen√≥is Totais',\n",
    "                        'flavanoids': 'Flavonoides',\n",
    "                        'nonflavanoid_phenols': 'Fen√≥is N√£o Flavonoides',\n",
    "                        'proanthocyanins': 'Proantocianidinas',\n",
    "                        'color_intensity': 'Intensidade da Cor',\n",
    "                        'hue': 'Tonalidade',\n",
    "                        'od280/od315_of_diluted_wines': 'DO280/DO315 de vinhos dilu√≠dos',\n",
    "                        'proline': 'Prolina'\n",
    "                        })\n",
    "\n",
    "# E exibimos as 5 primeiras linhas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153ad946",
   "metadata": {},
   "source": [
    "Com o objetivo de exemplificar alguns t√≥picos abaixo, iremos treinar um modelo simples de **KNN (K-Nearest Neighbors)**, um classificador que ser√° explicado em detalhes no M√≥dulo 3. Por ora, basta saber que ele classifica observa√ß√µes com base nos \"k vizinhos mais pr√≥ximos\" no espa√ßo de caracter√≠sticas.\n",
    "\n",
    "O bloco de c√≥digo abaixo cria, treina e faz previs√µes de um modelo da maneira mais simples poss√≠vel para que o utilizemos para mostrar como implementar em Python os t√≥picos que iremos cobrir em seguida. Ele pode ser utilizado como uma base para o projeto que voc√™ for fazer para praticar os conceitos aprendidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a429d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa o modelo KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Instancia o modelo KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Separa os dados em vari√°veis independentes (X) e dependentes (y)\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "\n",
    "# Utiliza o m√©todo train_test_split para dividir os dados em conjuntos de treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Divide os dados em 80% para treino e 20% para teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Treina o modelo KNN com os dados de treino\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Faz previs√µes com os dados de teste\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dd015c",
   "metadata": {},
   "source": [
    "<a id='metricas-avaliacao'></a>\n",
    "\n",
    "### **M√©tricas de Avalia√ß√£o para Classifica√ß√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ee6b3d",
   "metadata": {},
   "source": [
    "#### **Acur√°cia**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c60b78",
   "metadata": {},
   "source": [
    "A Acur√°cia √© o m√©todo mais simples e direto de se avaliar o resultado gerado por um modelo de Classifica√ß√£o\n",
    "\n",
    "Em resumo, ela mostra a **porcentagem de classifica√ß√µes corretas que o modelo fez**. Pensando de outra forma, a acur√°cia √© a **soma das previs√µes corretas** dividida pelo **total de previs√µes que o modelo fez**.\n",
    "\n",
    "A f√≥rmula que define a Acur√°cia √© a seguinte:\n",
    "\n",
    "$$\n",
    "ACC = \\frac{TP + TN}{TP + TN + FP + FN} \n",
    "$$\n",
    "\n",
    "Onde:\n",
    "\n",
    "$TP$ = True Positive, $TN$ = True Negative, $FP$ = False Positive, $FN$ = False Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb20732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa a fun√ß√£o de acur√°cia do sklearn metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calcula a acur√°cia\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Acur√°cia do modelo KNN: {accuracy:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a876e6",
   "metadata": {},
   "source": [
    "#### **Precis√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a378f2",
   "metadata": {},
   "source": [
    "Refere-se √† propor√ß√£o de previs√µes positivas corretas em rela√ß√£o ao total de previs√µes positivas feitas pelo modelo. A f√≥rmula da m√©tricas de Precis√£o √© a seguinte:\n",
    "\n",
    "$$\n",
    "Precison = \\frac{TP} {TP + FP}\n",
    "$$\n",
    "\n",
    "A Precis√£o √© bastante usada quando o objetivo √© limitar o n√∫mero de falsos positivos. Um exemplo √© um modelo que tenta prever se um novo rem√©dio sera efetivo no tratamento de uma doen√ßa. Nesse caso, √© fundamental que o modelo minimize os falsos positivos para uma correta mensura√ß√£o da efic√°cia do rem√©dio. Esse √© um caso em que √© fundamental o modelo possuir uma alta precis√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781b97a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a precis√£o do modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Calcula a precis√£o\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(f'Precis√£o do modelo KNN: {precision:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a2b42",
   "metadata": {},
   "source": [
    "#### **Recall (ou Sensitivity)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9feb8d",
   "metadata": {},
   "source": [
    "Recall, tamb√©m chamado de Sensitivity em alguns materiais, mede quanto das observa√ß√µes que s√£o positivas no conjunto de dados foram capturadas corretamente pelo modelo. \n",
    "\n",
    "$$\n",
    "Sensitivity=\\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "Essa m√©trica √© crucial quando √© essencial capturar todos os casos positivos, como no diagn√≥stico de doen√ßas graves ou detec√ß√£o de fraudes. Ou seja, queremos minimizar a ocorr√™ncia de falsos negativos. No exemplo de diagn√≥stico de uma doen√ßa, √© fundamental que n√£o deixemos nenhum paciente doente n√£o ser identificado corretamente pelo modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b3715c",
   "metadata": {},
   "source": [
    "üìù**Observa√ß√£o:**\n",
    "\n",
    "Existe um trade-off entre otimizar o **recall** e otimizar a **precis√£o**. √â poss√≠vel obter um recall perfeito de forma trivial se voc√™ prever que todas as amostras pertencem √† classe positiva ‚Äî dessa forma, n√£o haver√° falsos negativos, mas tamb√©m n√£o haver√° verdadeiros negativos. No entanto, ao prever todas as amostras como positivas, haver√° muitos falsos positivos, o que far√° com que a precis√£o seja muito baixa.\n",
    "\n",
    "Por outro lado, se voc√™ encontrar um modelo que prev√© como positiva apenas a √∫nica amostra da qual tem total certeza (supondo que essa amostra seja realmente positiva) e classifica todas as outras como negativas, a precis√£o ser√° perfeita. Contudo, o recall ser√° muito ruim, pois o modelo deixar√° de identificar outras amostras positivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a5be9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula o recall do modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Calcula o recall\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Recall do modelo KNN: {recall:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f3411c",
   "metadata": {},
   "source": [
    "#### **F1-Score**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a185d20",
   "metadata": {},
   "source": [
    "Vimos que tanto a Precis√£o quanto o Recall s√£o importantes medidas para avaliar um modelo de classifica√ß√£o. Como vimos, devemos fazer um trade-off entre as duas m√©tricas e analisar ambas para garantirmos que estamos com um bom modelo.\n",
    "\n",
    "Uma maneira de sumarizar ambas as m√©tricas em uma s√≥ √© o chamado **F1-Score**. Ele √© a m√©dia harmonica entre a Precis√£o e o Recall.\n",
    "\n",
    "$$\n",
    "F1-Score = {2}\\times{\\frac{\\text{Precision}\\times\\text{Recall}}{\\text{Precision}+\\text{Recall}}}\n",
    "$$\n",
    "\n",
    "O F1-Score pode ser uma medida melhor que a acur√°cia em conjunto de dados em classifica√ß√£o bin√°ria desbalanceada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc11475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula o F1-score do modelo\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calcula o F1-score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'F1-score do modelo KNN: {f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635ef1d6",
   "metadata": {},
   "source": [
    "#### **Curva ROC-AUC**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6690a6e4",
   "metadata": {},
   "source": [
    "A curva ROC (Receiver Operation Characteristcs) √© uma curva em um gr√°fico que coloca a taxa de false positive (FPR) contra a taxa de true positive (TPR). Perceba que a taxa de true positive √© apenas outro nome para o Recall enquanto a taxa de false positive √© a fra√ß√£o de falsos positivos em rela√ß√£o a todos as observa√ß√µes classificadas como negativas na nossa base de dados. \n",
    "\n",
    "$$\n",
    "FPR = {\\frac{FP}{FP+TN}}\n",
    "$$\n",
    "\n",
    "<p align='center'>\n",
    "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjhApq1sW6tLaFEXU4jK9g5YzvQBsudIhRUNkSBSYldIPaQ1Rwny1Z7Sj-Rt_8W2CCVKGCMDqu5GoSu4Cao1rAkfwVjgPfINcRuJTGjR-JPXbxY7NtgKQbFYUT2z6IfOAaeZadKVjdvQlkSG7JbDntxsUXWatk1tOUk0XPGBzbnKIRL6f929n8u3Pk1alQf/s1600-rw/roc.png\" width=\"500\"></img>\n",
    "</p>\n",
    "\n",
    "Na curva ROC, a curva ideal √© pr√≥xima ao canto superior esquerdo. Perceba que pr√≥ximo deste ponto √© **maximizada** a taxa de True Positives e **minimizada** a taxa de False Positives.\n",
    "\n",
    "As vezes queremos resumir a informa√ß√£o fornecida pela curva ROC em um simples n√∫mero. √â aqui que entra a sigla AUC. Ela significa Area Under the Curve (√Årea abaixo da Curva). Ou seja, podemos calcular a √°rea abaixo da curva ROC para avaliarmos a qualidade do modelo.\n",
    "\n",
    "Intuitivamente, √© percept√≠vel que queremos que essa √°rea tenha o maior valor poss√≠vel. Isso acontece porque desejamos que a curva ROC alcance o mais pr√≥ximo poss√≠vel do canto superior esquerdo (no limite, chegando no n√∫mero 1 do eixo vertical). Dessa forma, quanto maior o valor da AUC, melhor a performance do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfef398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constr√≥i a curva ROC e calcula a AUC (Multiclasse)\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "\n",
    "# Calcula as probabilidades de cada classe\n",
    "y_prob = knn.predict_proba(X_test)\n",
    "\n",
    "# Binariza os targets para One-vs-Rest (OvR)\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2])\n",
    "\n",
    "# Plota a curva ROC para cada classe\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for i in range(3):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'Classe {i} (AUC = {roc_auc:.2f})')\n",
    "    print(f'AUC da Classe {i}: {roc_auc:.5f}')\n",
    "\n",
    "# Adiciona diagonal (classificador aleat√≥rio)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Classificador Aleat√≥rio')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falsos Positivos')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "plt.title('Curva ROC (One-vs-Rest) - Classifica√ß√£o Multiclasse')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d46a8cd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<-- [**Anterior: Modelos e Valida√ß√£o**](01_modelos_validacao.ipynb) | [**Pr√≥ximo: M√©tricas de Regress√£o**](03_metricas_regressao.ipynb) -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
